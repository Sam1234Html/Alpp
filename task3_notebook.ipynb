# Cell 1: Imports and Setup
import numpy as np
import pandas as pd
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns

print("Libraries loaded successfully.")

# Cell 2: Load and Initial Preprocessing
# Load the dataset (using the common sklearn version of the UCI dataset)
data = load_breast_cancer(as_frame=True)
df = data.frame
# df['target_names'] = data.target_names[data.target] # Optional column

print(f"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.")
print("First 5 rows of the dataset:")
print(df.head())
print("\nMissing values check (Max should be 0):", df.isnull().sum().max())

# Cell 3: Feature Engineering - Map to 'Issue Priority'
# Goal: Predict issue priority (high/medium/low).
# Since the dataset is binary (Malignant/Benign), we map:
# 1 (Malignant) -> High Priority (Critical Issue)
# 0 (Benign)    -> Medium Priority (Standard Issue)
# We drop the original target column 'target'

df['Issue_Priority'] = df['target'].map({1: 'High', 0: 'Medium'})
df = df.drop(columns=['target'])

print("\nPriority distribution:")
print(df['Issue_Priority'].value_counts())

# Cell 4: Prepare Data for Modeling
# Define Features (X) and Target (y)
X = df.drop(columns=['Issue_Priority'])
y = df['Issue_Priority']

# Encode the categorical target variable ('High'/'Medium') into integers
le = LabelEncoder()
y_encoded = le.fit_transform(y)
# Check the mapping: le.classes_ shows ['High', 'Medium']
print("\nTarget Classes:", le.classes_)

# Split the data into training and testing sets (80/20 split)
X_train, X_test, y_train, y_test = train_test_split(
    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
)

print(f"\nTraining set size: {X_train.shape[0]} samples")
print(f"Testing set size: {X_test.shape[0]} samples")

# Cell 5: Train the Random Forest Model
# Initialize and train the Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
print("\nTraining Random Forest Classifier...")
rf_model.fit(X_train, y_train)
print("Training complete.")

# Cell 6: Evaluate Model and Calculate Metrics
# Make predictions on the test set
y_pred = rf_model.predict(X_test)

# Decode predictions back to 'High'/'Medium' labels for report
y_test_labels = le.inverse_transform(y_test)
y_pred_labels = le.inverse_transform(y_pred)

# Calculate performance metrics
accuracy = accuracy_score(y_test, y_pred)
# Use 'macro' average F1-score as it treats both classes equally
f1_macro = f1_score(y_test, y_pred, average='macro')

# Display performance metrics (Deliverable)
print("\n--- Model Performance Metrics (Random Forest) ---")
print(f"Accuracy Score: {accuracy:.4f}")
print(f"F1-Score (Macro): {f1_macro:.4f}")
print("\nDetailed Classification Report:")
print(classification_report(y_test_labels, y_pred_labels))
print("-" * 50)
